"""
PDF Processing Service for MediTalks
Handles PDF text extraction and processing using Google Gemini AI
"""

import os
import logging
import PyPDF2
import pdfplumber
import google.generativeai as genai
from typing import Dict, Any, Optional
from io import BytesIO
from langdetect import detect, DetectorFactory
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Set seed for consistent language detection
DetectorFactory.seed = 0

logger = logging.getLogger(__name__)

class PDFProcessingService:
    """Service for processing PDF documents and extracting text"""
    
    def __init__(self):
        self.api_key = os.getenv('GEMINI_API_KEY')
        self.model = None
        self._initialize_gemini()
    
    def _initialize_gemini(self):
        """Initialize Google Gemini AI for PDF processing"""
        try:
            if not self.api_key:
                logger.error("GEMINI_API_KEY not found in environment variables")
                return False
            
            genai.configure(api_key=self.api_key)
            self.model = genai.GenerativeModel('gemini-1.5-flash')
            logger.info("Gemini AI initialized for PDF processing")
            return True
            
        except Exception as e:
            logger.error(f"Failed to initialize Gemini AI: {str(e)}")
            return False
    
    def extract_text_from_pdf(self, file, target_language: str = 'en') -> Dict[str, Any]:
        """
        Extract text from PDF file
        
        Args:
            file: PDF file object
            target_language (str): Target language code
            
        Returns:
            Dict containing extraction result
        """
        try:
            # Reset file pointer
            file.seek(0)
            
            # Try pdfplumber first (better for complex layouts)
            extracted_text = self._extract_with_pdfplumber(file)
            
            if not extracted_text or len(extracted_text.strip()) < 10:
                # Fallback to PyPDF2
                file.seek(0)
                extracted_text = self._extract_with_pypdf2(file)
            
            if not extracted_text or len(extracted_text.strip()) < 10:
                return {
                    'success': False,
                    'error': 'Could not extract text from PDF',
                    'text': ''
                }
            
            # Detect language
            detected_language = self._detect_language(extracted_text)
            
            # Clean and process text
            cleaned_text = self._clean_text(extracted_text)
            
            return {
                'success': True,
                'text': cleaned_text,
                'detected_language': detected_language,
                'word_count': len(cleaned_text.split()),
                'char_count': len(cleaned_text)
            }
            
        except Exception as e:
            logger.error(f"Error extracting text from PDF: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'text': ''
            }
    
    def _extract_with_pdfplumber(self, file) -> str:
        """Extract text using pdfplumber"""
        try:
            text_content = []
            
            with pdfplumber.open(file) as pdf:
                for page_num, page in enumerate(pdf.pages):
                    try:
                        page_text = page.extract_text()
                        if page_text:
                            text_content.append(page_text)
                        
                        # Limit to first 10 pages for performance
                        if page_num >= 9:
                            break
                            
                    except Exception as e:
                        logger.warning(f"Error extracting page {page_num + 1}: {str(e)}")
                        continue
            
            return '\n'.join(text_content)
            
        except Exception as e:
            logger.error(f"pdfplumber extraction failed: {str(e)}")
            return ""
    
    def _extract_with_pypdf2(self, file) -> str:
        """Extract text using PyPDF2 as fallback"""
        try:
            text_content = []
            pdf_reader = PyPDF2.PdfReader(file)
            
            # Limit to first 10 pages
            max_pages = min(len(pdf_reader.pages), 10)
            
            for page_num in range(max_pages):
                try:
                    page = pdf_reader.pages[page_num]
                    page_text = page.extract_text()
                    if page_text:
                        text_content.append(page_text)
                        
                except Exception as e:
                    logger.warning(f"Error extracting page {page_num + 1}: {str(e)}")
                    continue
            
            return '\n'.join(text_content)
            
        except Exception as e:
            logger.error(f"PyPDF2 extraction failed: {str(e)}")
            return ""
    
    def _detect_language(self, text: str) -> str:
        """Detect the language of extracted text"""
        try:
            if len(text.strip()) < 10:
                return "unknown"
            
            # Use first 1000 characters for detection
            sample_text = text[:1000]
            detected = detect(sample_text)
            
            # Map common language codes to full names
            language_map = {
                'en': 'English',
                'th': 'Thai',
                'vi': 'Vietnamese',
                'ms': 'Malay',
                'km': 'Khmer',
                'tl': 'Tagalog',
                'fil': 'Filipino'
            }
            
            return language_map.get(detected, detected)
            
        except Exception as e:
            logger.warning(f"Language detection failed: {str(e)}")
            return "unknown"
    
    def _clean_text(self, text: str) -> str:
        """Clean and normalize extracted text"""
        if not text:
            return ""
        
        # Remove excessive whitespace
        import re
        
        # Replace multiple spaces with single space
        text = re.sub(r'\s+', ' ', text)
        
        # Remove excessive line breaks
        text = re.sub(r'\n\s*\n\s*\n', '\n\n', text)
        
        # Clean up common PDF artifacts
        text = re.sub(r'[^\w\s\.\,\!\?\;\:\-\(\)\[\]\{\}\"\'\/\\\n]', ' ', text)
        
        return text.strip()
    
    def summarize_pdf_content(self, text: str, target_language: str = 'en') -> str:
        """
        Summarize PDF content using Gemini AI
        
        Args:
            text (str): Extracted text to summarize
            target_language (str): Target language for summary
            
        Returns:
            str: Summarized content
        """
        try:
            if not self.model:
                return self._simple_summary(text)
            
            prompt = f"""
Summarize the following medical document text in {target_language}. 
Focus on key medical information, instructions, and important details.
Keep the summary concise but comprehensive.

Text to summarize:
{text[:3000]}  # Limit text length for API
"""
            
            response = self.model.generate_content(prompt)
            
            if response.text:
                return response.text.strip()
            else:
                return self._simple_summary(text)
                
        except Exception as e:
            logger.error(f"Error summarizing with Gemini: {str(e)}")
            return self._simple_summary(text)
    
    def generate_detailed_explanation(self, text: str, cultural_context: str, target_language: str = 'en') -> str:
        """
        Generate detailed explanation of PDF content with cultural considerations
        
        Args:
            text (str): Extracted PDF text
            cultural_context (str): Cultural context for adaptation
            target_language (str): Target language for explanation
            
        Returns:
            str: Detailed explanation
        """
        try:
            if not self.model:
                return self._fallback_detailed_explanation(text, cultural_context)
            
            # Cultural context mapping for better prompting
            context_mapping = {
                'tagalog-rural': 'rural Filipino communities with traditional family values and respect for elders',
                'thai-low-literacy': 'Thai communities with limited literacy, Buddhist influences, and traditional medicine awareness',
                'khmer-indigenous': 'indigenous Khmer communities with strong Buddhist beliefs and traditional healing practices',
                'vietnamese-elderly': 'elderly Vietnamese population with Confucian values and family-centered healthcare',
                'malay-traditional': 'traditional Malay communities with Islamic influences and family-centered care'
            }
            
            context_description = context_mapping.get(cultural_context, 'general healthcare context')
            
            language_names = {
                'en': 'English',
                'th': 'Thai',
                'vi': 'Vietnamese', 
                'ms': 'Malay',
                'km': 'Khmer',
                'tl': 'Tagalog'
            }
            
            language_name = language_names.get(target_language, 'English')
            
            prompt = f"""
You are a medical communication expert. Analyze the following medical document and provide a comprehensive summary ONLY in {language_name}. Do not use English in your response.

The target audience is: {context_description}

Medical Document Text:
{text[:3000]}

Provide a complete summary in {language_name} that includes:
1. What this medical document is about
2. Key medical information in simple terms
3. Important instructions for the patient/family
4. Any warnings or precautions
5. Cultural considerations for this community

Write everything in {language_name} only. Make it culturally appropriate and easy to understand.
"""
            
            response = self.model.generate_content(prompt)
            
            if response.text:
                return response.text.strip()
            else:
                return self._fallback_detailed_explanation(text, cultural_context)
                
        except Exception as e:
            logger.error(f"Error generating detailed explanation: {str(e)}")
            return self._fallback_detailed_explanation(text, cultural_context)
    
    def generate_cultural_solutions(self, text: str, cultural_context: str, target_language: str = 'en') -> list:
        """
        Generate actionable, culturally appropriate solutions based on PDF content
        
        Args:
            text (str): Extracted PDF text
            cultural_context (str): Cultural context for adaptation
            target_language (str): Target language for solutions
            
        Returns:
            list: List of actionable solutions
        """
        try:
            if not self.model:
                return self._fallback_solutions(text, cultural_context)
            
            context_mapping = {
                'tagalog-rural': 'rural Filipino families who value community input and respect traditional practices',
                'thai-low-literacy': 'Thai communities with limited literacy who prefer simple, visual explanations',
                'khmer-indigenous': 'indigenous Khmer communities who respect traditional healing alongside modern medicine',
                'vietnamese-elderly': 'elderly Vietnamese patients who prefer family involvement in healthcare decisions',
                'malay-traditional': 'traditional Malay families who consider Islamic principles in healthcare'
            }
            
            context_description = context_mapping.get(cultural_context, 'general healthcare context')
            
            language_names = {
                'en': 'English',
                'th': 'Thai',
                'vi': 'Vietnamese',
                'ms': 'Malay', 
                'km': 'Khmer',
                'tl': 'Tagalog'
            }
            
            language_name = language_names.get(target_language, 'English')
            
            prompt = f"""
Based on this medical document, provide ONLY actionable solutions in {language_name} for: {context_description}

Medical Document:
{text[:2500]}

Provide 5-7 specific solutions in {language_name} that are:
1. Culturally appropriate and respectful
2. Practical and actionable
3. Consider family/community involvement
4. Respect traditional practices while emphasizing medical compliance
5. Include specific steps to take

Write ONLY in {language_name}. Format as a numbered list of clear action items.
"""
            
            response = self.model.generate_content(prompt)
            
            if response.text:
                # Parse the solutions into a list
                solutions = []
                lines = response.text.strip().split('\n')
                for line in lines:
                    line = line.strip()
                    # Look for numbered or bulleted items
                    if line and (line[0].isdigit() or line.startswith('-') or line.startswith('â€¢')):
                        # Clean up the solution text
                        clean_solution = line.lstrip('0123456789.-â€¢').strip()
                        if clean_solution:
                            solutions.append(clean_solution)
                
                return solutions[:7]  # Limit to 7 solutions
            else:
                return self._fallback_solutions(text, cultural_context)
                
        except Exception as e:
            logger.error(f"Error generating cultural solutions: {str(e)}")
            return self._fallback_solutions(text, cultural_context)
    
    def extract_medical_concepts(self, text: str, target_language: str = 'en') -> Dict[str, list]:
        """
        Extract medical concepts, key terms, and instructions from PDF text
        
        Args:
            text (str): Extracted PDF text
            target_language (str): Target language for concepts
            
        Returns:
            Dict: Dictionary containing key_terms, medical_concepts, and instructions
        """
        try:
            if not self.model:
                return self._fallback_medical_concepts(text, target_language)
            
            language_names = {
                'en': 'English',
                'th': 'Thai',
                'vi': 'Vietnamese',
                'ms': 'Malay',
                'km': 'Khmer', 
                'tl': 'Tagalog'
            }
            
            language_name = language_names.get(target_language, 'English')
            
            prompt = f"""
Analyze this medical document and extract key information in {language_name} ONLY. Do not use English.

Medical Document:
{text[:2500]}

Provide in {language_name}:
1. Key Medical Terms (5-8 important medical words/phrases)
2. Medical Concepts (3-5 main medical ideas or conditions)
3. Important Instructions (3-5 specific things the patient must do)

Format your response as:
KEY TERMS:
- term 1 in {language_name}
- term 2 in {language_name}

MEDICAL CONCEPTS:
- concept 1 in {language_name}
- concept 2 in {language_name}

INSTRUCTIONS:
- instruction 1 in {language_name}
- instruction 2 in {language_name}

Write everything in {language_name} only.
"""
            
            response = self.model.generate_content(prompt)
            
            if response.text:
                return self._parse_medical_analysis(response.text)
            else:
                return self._fallback_medical_concepts(text)
                
        except Exception as e:
            logger.error(f"Error extracting medical concepts: {str(e)}")
            return self._fallback_medical_concepts(text, target_language)
    
    def _parse_medical_analysis(self, analysis_text: str) -> Dict[str, list]:
        """Parse the medical analysis response into structured data"""
        result = {
            'key_terms': [],
            'medical_concepts': [],
            'instructions': []
        }
        
        current_section = None
        lines = analysis_text.split('\n')
        
        for line in lines:
            line = line.strip()
            if 'KEY TERMS' in line.upper():
                current_section = 'key_terms'
            elif 'MEDICAL CONCEPTS' in line.upper():
                current_section = 'medical_concepts'
            elif 'INSTRUCTIONS' in line.upper():
                current_section = 'instructions'
            elif line.startswith('-') or line.startswith('â€¢') and current_section:
                clean_item = line.lstrip('-â€¢').strip()
                if clean_item and current_section in result:
                    result[current_section].append(clean_item)
        
        return result
    
    def _fallback_detailed_explanation(self, text: str, cultural_context: str) -> str:
        """Fallback explanation when Gemini is not available"""
        explanations = {
            'tagalog-rural': f"Ang dokumentong ito ay naglalaman ng mahalagang impormasyon tungkol sa inyong kalusugan. Makipag-ugnayan sa inyong doktor para sa karagdagang paliwanag.",
            'thai-low-literacy': f"à¹€à¸­à¸à¸ªà¸²à¸£à¸™à¸µà¹‰à¸¡à¸µà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ªà¸³à¸„à¸±à¸à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸ªà¸¸à¸‚à¸ à¸²à¸à¸‚à¸­à¸‡à¸„à¸¸à¸“ à¸à¸£à¸¸à¸“à¸²à¸›à¸£à¸¶à¸à¸©à¸²à¹à¸à¸—à¸¢à¹Œà¹€à¸à¸·à¹ˆà¸­à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡",
            'khmer-indigenous': f"á¯á€áŸá¶ášá“áŸáŸ‡á˜á¶á“á–áŸááŸŒá˜á¶á“áŸáŸ†áá¶á“áŸ‹á¢áŸ†á–á¸áŸá»áá—á¶á–ášá”áŸáŸ‹á¢áŸ’á“á€ áŸá¼á˜á–á·á‚áŸ’ášáŸ„áŸ‡á‡á¶á˜á½á™áœáŸá‡áŸ’á‡á”ááŸ’áŒá·ááŸá˜áŸ’ášá¶á”áŸ‹á–áŸááŸŒá˜á¶á“á”á“áŸ’ááŸ‚á˜",
            'vietnamese-elderly': f"TÃ i liá»‡u nÃ y chá»©a thÃ´ng tin quan trá»ng vá» sá»©c khá»e cá»§a quÃ½ vá»‹. Xin hÃ£y tham kháº£o Ã½ kiáº¿n bÃ¡c sÄ© Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t.",
            'malay-traditional': f"Dokumen ini mengandungi maklumat penting mengenai kesihatan anda. Sila rujuk doktor untuk maklumat lanjut."
        }
        
        return explanations.get(cultural_context, "Dokumen ini mengandungi maklumat penting mengenai kesihatan anda.")
    
    def _fallback_solutions(self, text: str, cultural_context: str) -> list:
        """Fallback solutions when Gemini is not available"""
        solutions_by_context = {
            'tagalog-rural': [
                "Makipag-ugnayan sa inyong doktor para sa personal na payo",
                "Sundin ang mga tagubilin sa paginom ng gamot",
                "Magtakda ng regular na appointment para sa follow-up",
                "Bantayan ang mga sintomas at iulat ang mga pagbabago",
                "Makipag-ugnayan sa inyong pamilya tungkol sa treatment plan"
            ],
            'thai-low-literacy': [
                "à¸›à¸£à¸¶à¸à¸©à¸²à¹à¸à¸—à¸¢à¹Œà¹€à¸à¸·à¹ˆà¸­à¸£à¸±à¸šà¸„à¸³à¹à¸™à¸°à¸™à¸³à¸ªà¹ˆà¸§à¸™à¸šà¸¸à¸„à¸„à¸¥",
                "à¸—à¸²à¸™à¸¢à¸²à¸•à¸²à¸¡à¸—à¸µà¹ˆà¹à¸à¸—à¸¢à¹Œà¸ªà¸±à¹ˆà¸‡",
                "à¸™à¸±à¸”à¸«à¸¡à¸²à¸¢à¹à¸à¸—à¸¢à¹Œà¹€à¸›à¹‡à¸™à¸›à¸£à¸°à¸ˆà¸³",
                "à¸ªà¸±à¸‡à¹€à¸à¸•à¸­à¸²à¸à¸²à¸£à¹à¸¥à¸°à¸£à¸²à¸¢à¸‡à¸²à¸™à¸à¸²à¸£à¹€à¸›à¸¥à¸µà¹ˆà¸¢à¸™à¹à¸›à¸¥à¸‡",
                "à¸‚à¸­à¹ƒà¸«à¹‰à¸„à¸£à¸­à¸šà¸„à¸£à¸±à¸§à¸Šà¹ˆà¸§à¸¢à¸ˆà¸³à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸à¸²à¸£à¸£à¸±à¸à¸©à¸²"
            ],
            'khmer-indigenous': [
                "á–á·á‚áŸ’ášáŸ„áŸ‡á‡á¶á˜á½á™áœáŸá‡áŸ’á‡á”ááŸ’áŒá·ááŸá˜áŸ’ášá¶á”áŸ‹á€á¶ášááŸ‚á“á¶áŸ†á•áŸ’á‘á¶á›áŸ‹ááŸ’á›á½á“",
                "á‰áŸ‰á¶áŸ†ááŸ’á“á¶áŸ†áá¶á˜á€á¶ášááŸ‚á“á¶áŸ†",
                "á€ááŸ‹ááŸ’ášá¶á“áŸ…áœáŸá‡áŸ’á‡á”ááŸ’áŒá·áá‡á¶á‘áŸ€á„á‘á¶ááŸ‹",
                "áŸá„áŸ’á€áŸáá˜á¾á›ášáŸ„á‚áŸá‰áŸ’á‰á¶á“á·á„ášá¶á™á€á¶ášááŸá€á¶ášá•áŸ’á›á¶áŸáŸ‹á”áŸ’áá¼áš",
                "á–á·á—á¶á€áŸ’áŸá¶á‡á¶á˜á½á™á‚áŸ’ášá½áŸá¶ášá¢áŸ†á–á¸á•áŸ‚á“á€á¶ášá–áŸ’á™á¶á”á¶á›"
            ],
            'vietnamese-elderly': [
                "Tham kháº£o Ã½ kiáº¿n bÃ¡c sÄ© Ä‘á»ƒ nháº­n tÆ° váº¥n cÃ¡ nhÃ¢n",
                "Uá»‘ng thuá»‘c theo Ä‘Ãºng chá»‰ Ä‘á»‹nh",
                "Äáº·t lá»‹ch tÃ¡i khÃ¡m Ä‘á»‹nh ká»³",
                "Theo dÃµi cÃ¡c triá»‡u chá»©ng vÃ  bÃ¡o cÃ¡o thay Ä‘á»•i",
                "Tháº£o luáº­n vá»›i gia Ä‘Ã¬nh vá» káº¿ hoáº¡ch Ä‘iá»u trá»‹"
            ],
            'malay-traditional': [
                "Rujuk doktor untuk nasihat peribadi",
                "Ikut arahan pengambilan ubat",
                "Buat temujanji susulan berkala",
                "Pantau simptom dan laporkan perubahan",
                "Berbincang dengan keluarga mengenai rancangan rawatan"
            ]
        }
        
        return solutions_by_context.get(cultural_context, [
            "Rujuk doktor untuk maklumat lanjut",
            "Ikut semua arahan perubatan",
            "Pantau kesihatan dengan kerap"
        ])
    
    def _fallback_medical_concepts(self, text: str, target_language: str = 'en') -> Dict[str, list]:
        """Fallback medical concept extraction in appropriate language"""
        # Map language codes to cultural contexts for fallback
        language_to_context = {
            'tl': 'tagalog-rural',
            'th': 'thai-low-literacy', 
            'km': 'khmer-indigenous',
            'vi': 'vietnamese-elderly',
            'ms': 'malay-traditional',
            'en': 'malay-traditional'  # Default to Malay as fallback
        }
        
        context_key = language_to_context.get(target_language, 'malay-traditional')
        
        concepts_by_context = {
            'tagalog-rural': {
                'key_terms': ['gamot', 'doktor', 'ospital', 'sakit', 'lunas'],
                'medical_concepts': ['Pangangalaga ng kalusugan', 'Pagsunod sa gamot', 'Regular na checkup'],
                'instructions': ['Uminom ng gamot ayon sa tagubilin', 'Makipag-ugnayan sa doktor kung may tanong']
            },
            'thai-low-literacy': {
                'key_terms': ['à¸¢à¸²', 'à¸«à¸¡à¸­', 'à¹‚à¸£à¸‡à¸à¸¢à¸²à¸šà¸²à¸¥', 'à¸­à¸²à¸à¸²à¸£', 'à¸à¸²à¸£à¸£à¸±à¸à¸©à¸²'],
                'medical_concepts': ['à¸à¸²à¸£à¸”à¸¹à¹à¸¥à¸ªà¸¸à¸‚à¸ à¸²à¸', 'à¸à¸²à¸£à¸—à¸²à¸™à¸¢à¸²', 'à¸à¸²à¸£à¸•à¸£à¸§à¸ˆà¸ªà¸¸à¸‚à¸ à¸²à¸'],
                'instructions': ['à¸—à¸²à¸™à¸¢à¸²à¸•à¸²à¸¡à¹à¸à¸—à¸¢à¹Œà¸ªà¸±à¹ˆà¸‡', 'à¸•à¸´à¸”à¸•à¹ˆà¸­à¹à¸à¸—à¸¢à¹Œà¸«à¸²à¸à¸¡à¸µà¸‚à¹‰à¸­à¸ªà¸‡à¸ªà¸±à¸¢']
            },
            'khmer-indigenous': {
                'key_terms': ['ááŸ’á“á¶áŸ†', 'áœáŸá‡áŸ’á‡á”ááŸ’áŒá·á', 'á˜á“áŸ’á‘á¸ášá–áŸá‘áŸ’á™', 'ášáŸ„á‚áŸá‰áŸ’á‰á¶', 'á€á¶ášá–áŸ’á™á¶á”á¶á›'],
                'medical_concepts': ['á€á¶ášááŸ‚á‘á¶áŸ†áŸá»áá—á¶á–', 'á€á¶ášá‰áŸ‰á¶áŸ†ááŸ’á“á¶áŸ†', 'á€á¶ášá–á·á“á·ááŸ’á™áŸá»áá—á¶á–'],
                'instructions': ['á‰áŸ‰á¶áŸ†ááŸ’á“á¶áŸ†áá¶á˜á€á¶ášááŸ‚á“á¶áŸ†', 'á‘á¶á€áŸ‹á‘á„áœáŸá‡áŸ’á‡á”ááŸ’áŒá·áá”áŸ’ášáŸá·á“á”á¾á˜á¶á“áŸáŸ†áá½áš']
            },
            'vietnamese-elderly': {
                'key_terms': ['thuá»‘c', 'bÃ¡c sÄ©', 'bá»‡nh viá»‡n', 'triá»‡u chá»©ng', 'Ä‘iá»u trá»‹'],
                'medical_concepts': ['ChÄƒm sÃ³c sá»©c khá»e', 'Uá»‘ng thuá»‘c Ä‘Ãºng cÃ¡ch', 'KhÃ¡m sá»©c khá»e Ä‘á»‹nh ká»³'],
                'instructions': ['Uá»‘ng thuá»‘c theo chá»‰ Ä‘á»‹nh', 'LiÃªn há»‡ bÃ¡c sÄ© náº¿u cÃ³ tháº¯c máº¯c']
            },
            'malay-traditional': {
                'key_terms': ['ubat', 'doktor', 'hospital', 'simptom', 'rawatan'],
                'medical_concepts': ['Penjagaan kesihatan', 'Pengambilan ubat', 'Pemeriksaan kesihatan'],
                'instructions': ['Ambil ubat mengikut arahan', 'Hubungi doktor jika ada pertanyaan']
            }
        }
        
        return concepts_by_context.get(context_key, concepts_by_context['malay-traditional'])

    def _simple_summary(self, text: str) -> str:
        """Simple fallback summary"""
        if not text:
            return "No content to summarize."
        
        # Simple approach: take first few sentences
        sentences = text.split('.')[:3]
        summary = '. '.join(sentences).strip()
        
        if len(summary) > 200:
            summary = summary[:200] + "..."
        
        return summary or "Document content extracted successfully."
    
    def analyze_with_gemini(self, text: str, cultural_context: str = 'general', target_language: str = 'en') -> Dict[str, Any]:
        """
        Enhanced PDF analysis using Gemini AI with cultural adaptation
        
        Args:
            text (str): Extracted text from PDF
            cultural_context (str): Cultural context for adaptation
            target_language (str): Target language for output
            
        Returns:
            Dict containing analysis result
        """
        try:
            if not self.model:
                logger.error("Gemini model not initialized")
                return {'success': False, 'error': 'Gemini AI not available'}
            
            # Build enhanced prompt for medical document analysis
            prompt = self._build_gemini_analysis_prompt(text, cultural_context, target_language)
            
            # Generate response using Gemini
            response = self.model.generate_content(prompt)
            
            if not response or not response.text:
                logger.error("Empty response from Gemini API")
                return {'success': False, 'error': 'Empty response from Gemini'}
            
            # Process and format the response
            analysis_result = self._process_gemini_response(response.text, target_language)
            
            return {
                'success': True,
                'summary': analysis_result,
                'source': 'gemini',
                'cultural_context': cultural_context,
                'target_language': target_language
            }
            
        except Exception as e:
            logger.error(f"Error in Gemini analysis: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    def _build_gemini_analysis_prompt(self, text: str, cultural_context: str, target_language: str) -> str:
        """Build enhanced prompt for Gemini analysis"""
        
        # Language-specific instructions
        language_instructions = {
            'en': 'Respond in clear, simple English',
            'tl': 'Mag-respond sa madaling unawain na Filipino/Tagalog',
            'th': 'à¸•à¸­à¸šà¹€à¸›à¹‡à¸™à¸ à¸²à¸©à¸²à¹„à¸—à¸¢à¸—à¸µà¹ˆà¹€à¸‚à¹‰à¸²à¹ƒà¸ˆà¸‡à¹ˆà¸²à¸¢',
            'vi': 'Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t dá»… hiá»ƒu',
            'ms': 'Jawab dalam Bahasa Melayu yang mudah difahami',
            'km': 'á†áŸ’á›á¾á™á‡á¶á—á¶áŸá¶ááŸ’á˜áŸ‚ášáŠáŸ‚á›á„á¶á™á™á›áŸ‹'
        }
        
        # Cultural context considerations
        cultural_notes = {
            'filipino': 'Consider Filipino healthcare practices, family involvement in medical decisions, and respect for authority figures.',
            'thai': 'Consider Thai Buddhist perspectives on health, traditional medicine integration, and family hierarchy in healthcare.',
            'vietnamese': 'Consider Vietnamese traditional medicine, family-centered care, and communication styles.',
            'malay': 'Consider Islamic perspectives on health, halal considerations, and community-centered healthcare.',
            'khmer': 'Consider Cambodian traditional healing practices, Buddhist beliefs, and extended family involvement.'
        }
        
        language_instruction = language_instructions.get(target_language, language_instructions['en'])
        cultural_note = cultural_notes.get(cultural_context, 'Consider general healthcare best practices.')
        
        prompt = f"""
You are a medical communication expert helping patients understand their medical documents.

DOCUMENT CONTENT:
{text[:3000]}  # Limit text to avoid token limits

INSTRUCTIONS:
1. {language_instruction}
2. {cultural_note}
3. Focus on practical, actionable information
4. Use simple, non-technical language
5. Highlight important warnings or instructions

ANALYSIS FORMAT:
Please provide a comprehensive analysis with these sections:

ğŸ¥ **DOCUMENT SUMMARY**
- Brief overview of what this document is about
- Main purpose (prescription, test results, discharge instructions, etc.)

ğŸ“‹ **KEY MEDICAL INFORMATION**
- Important medical terms explained in simple language
- Medications mentioned (names, purposes, dosages)
- Medical conditions or diagnoses

âš ï¸ **IMPORTANT INSTRUCTIONS**
- Things the patient MUST do
- Things to avoid
- Warning signs to watch for
- When to contact healthcare providers

ğŸ—“ï¸ **FOLLOW-UP CARE**
- Appointments or tests needed
- Timeline for medication or treatment
- Recovery expectations

ğŸ’¡ **PATIENT GUIDANCE**
- Practical tips for following instructions
- Questions to ask healthcare providers
- Resources for additional support

Make sure your response is culturally appropriate and considers the patient's likely concerns and questions.
"""
        
        return prompt
    
    def _process_gemini_response(self, response_text: str, target_language: str) -> str:
        """Process and format Gemini response"""
        try:
            # Clean up the response
            cleaned_response = response_text.strip()
            
            # Ensure proper formatting
            if not cleaned_response.startswith('ğŸ¥'):
                # Add a header if not present
                header = "ğŸ“„ **MEDICAL DOCUMENT ANALYSIS**\n\n"
                cleaned_response = header + cleaned_response
            
            # Add language-specific closing note
            closing_notes = {
                'en': "\n\nğŸ’¬ **Note**: If you have questions about this information, please contact your healthcare provider.",
                'tl': "\n\nğŸ’¬ **Paalala**: Kung may mga tanong kayo tungkol sa impormasyong ito, makipag-ugnayan sa inyong healthcare provider.",
                'th': "\n\nğŸ’¬ **à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸**: à¸«à¸²à¸à¸¡à¸µà¸„à¸³à¸–à¸²à¸¡à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸™à¸µà¹‰ à¸à¸£à¸¸à¸“à¸²à¸•à¸´à¸”à¸•à¹ˆà¸­à¸œà¸¹à¹‰à¹ƒà¸«à¹‰à¸šà¸£à¸´à¸à¸²à¸£à¸—à¸²à¸‡à¸à¸²à¸£à¹à¸à¸—à¸¢à¹Œà¸‚à¸­à¸‡à¸„à¸¸à¸“",
                'vi': "\n\nğŸ’¬ **LÆ°u Ã½**: Náº¿u báº¡n cÃ³ cÃ¢u há»i vá» thÃ´ng tin nÃ y, vui lÃ²ng liÃªn há»‡ vá»›i nhÃ  cung cáº¥p dá»‹ch vá»¥ chÄƒm sÃ³c sá»©c khá»e cá»§a báº¡n.",
                'ms': "\n\nğŸ’¬ **Nota**: Jika anda mempunyai soalan mengenai maklumat ini, sila hubungi penyedia penjagaan kesihatan anda.",
                'km': "\n\nğŸ’¬ **á…áŸ†áá¶áŸ†**: á”áŸ’ášáŸá·á“á”á¾á¢áŸ’á“á€á˜á¶á“áŸáŸ†áá½ášá¢áŸ†á–á¸á–áŸááŸŒá˜á¶á“á“áŸáŸ‡ áŸá¼á˜á‘á¶á€áŸ‹á‘á„á¢áŸ’á“á€á•áŸ’áá›áŸ‹áŸáŸáœá¶ááŸ‚á‘á¶áŸ†áŸá»áá—á¶á–ášá”áŸáŸ‹á¢áŸ’á“á€áŸ”"
            }
            
            closing_note = closing_notes.get(target_language, closing_notes['en'])
            cleaned_response += closing_note
            
            return cleaned_response
            
        except Exception as e:
            logger.error(f"Error processing Gemini response: {str(e)}")
            return response_text  # Return original if processing fails
